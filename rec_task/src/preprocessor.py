import numpy as np
import pandas as pd
from pathlib import Path
from typing import Tuple, Dict, List


class Preprocessor:
    def __init__(self, config: dict) -> None:
        self.config = config
        self.interim_dir = Path(config["file_path"]["interim_dir"])
        self.encode_cols = [
            "session_id_hash",
            "product_sku_hash",
            "product_action",
            "hashed_url",
            "price_bucket",
            "number_of_category_hash",
            "category_hash_first_level",
            "category_hash_second_level",
            "category_hash_third_level",
            "event_type",
        ]
        self.label_to_index_dict = {}
        self.index_to_label_dict = {}

    def run(
        self,
        train: pd.DataFrame,
        test: pd.DataFrame,
        sku_to_content: pd.DataFrame,
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        train["is_test"] = False
        test["is_test"] = True
        total = pd.concat([train, test], axis=0)
        self.get_query_features(total)
        total = self._filter_out(total)

        self.preprocessing_sku_to_content(sku_to_content)
        total = pd.merge(total, sku_to_content, on=["product_sku_hash"], how="left")

        self.get_time_features(total)
        self._label_encoding(total)
        self.fillna(total)

        train_preprocessed = total[total["is_test"] == False]
        test_preprocessed = total[total["is_test"] == True]
        return train_preprocessed, test_preprocessed

    @staticmethod
    def preprocessing_sku_to_content(sku_to_content: pd.DataFrame) -> None:
        sku_to_content["number_of_category_hash"] = (
            sku_to_content["category_hash"]
            .apply(
                lambda x: len(x.split("/")) if isinstance(x, str) else np.nan
            )
        )

    @staticmethod
    def fillna(df: pd.DataFrame) -> None:
        df["description_vector"] = (
            df["description_vector"]
            .apply(lambda x: x if isinstance(x, list) else [0.5] * 50)
        )
        df["image_vector"] = (
            df["image_vector"]
            .apply(lambda x: x if isinstance(x, list) else [0.5] * 50)
        )

    def get_time_features(self, df: pd.DataFrame) -> None:
        df["elapsed_time"] = (
            (
                df["server_timestamp_epoch_ms"]
                - df.groupby("session_id_hash")["server_timestamp_epoch_ms"].shift()
            ).fillna(0) / 1000   # ms -> sec
        )
        df["elapsed_time"] = (
            (df["elapsed_time"].astype(int) + 1)
            .clip(lower=1, upper=self.config["encoder_params"]["size_elapsed_time"] - 1)
        )

        df["hour"] = (df["server_timestamp"].dt.hour + 1).astype("int8")
        df["weekday"] = (df["server_timestamp"].dt.weekday + 1).astype("int8")
        df["weekend"] = df["weekday"].isin([6, 7]).astype("int8") + 1

    @staticmethod
    def get_query_features(df: pd.DataFrame) -> None:
        df["is_query"] = df.groupby("session_id_hash")["is_search"].transform("max").astype("int8") + 1

    def _label_encoding(self, df: pd.DataFrame) -> None:
        for col in self.encode_cols:
            index_series, label_to_index, index_to_label = self._label_encode_series(df[col].astype(str))
            df[col] = index_series
            self.label_to_index_dict[col] = label_to_index
            self.index_to_label_dict[col] = index_to_label

    @staticmethod
    def _label_encode_series(series: pd.Series) -> Tuple[pd.Series, dict, dict]:
        """https://github.com/coveooss/SIGIR-ecom-data-challenge/blob/main/baselines/create_session_rec_input.py#L31-L42
        """
        labels = sorted(set(series.dropna().unique()), reverse=True)   # avoid null value
        label_to_index = {l: idx + 1 for idx, l in enumerate(labels)}  # 0: padding id
        index_to_label = {v: k for k, v in label_to_index.items()}
        return series.map(label_to_index), label_to_index, index_to_label

    def _filter_out(self, df: pd.DataFrame) -> pd.DataFrame:
        # rows with pageview generated by item interaction
        original_rows = len(df)
        item_interactions = (
            df[df["product_action"].notnull()]
            [["session_id_hash", "hashed_url", "server_timestamp_epoch_ms"]]
            .drop_duplicates()
        )
        item_interactions["is_interaction"] = 1
        df = pd.merge(
            df,
            item_interactions[["session_id_hash", "hashed_url", "server_timestamp_epoch_ms", "is_interaction"]],
            on=["session_id_hash", "hashed_url", "server_timestamp_epoch_ms"],
            how="left",
        )
        assert original_rows == len(df), "original_rows != len(df)"
        df = df[~((df["is_interaction"] == 1) & (df["event_type"] == "pageview"))]

        # rows with query
        df = df.query("is_search == 0")

        # unseen from train data
        train_item_index_set = set(df.query("is_test == False")["product_sku_hash"].unique())
        df.loc[~df["product_sku_hash"].isin(train_item_index_set), "product_sku_hash"] = np.nan
        return df

    @staticmethod
    def get_session_sequences(df: pd.DataFrame) -> Dict[int, Dict[str, List]]:
        session_seqs = (
            df
            .groupby("session_id_hash")
            .agg({
                "product_sku_hash": list,
                "elapsed_time": list,
                "product_action": list,
                "hashed_url": list,
                "price_bucket": list,
                "number_of_category_hash": list,
                "category_hash_first_level": list,
                "category_hash_second_level": list,
                "category_hash_third_level": list,
                "description_vector": list,
                "image_vector": list,
                "event_type": list,
                "hour": list,
                "weekday": list,
                "weekend": list,
                "is_query": list,
            })
            .to_dict(orient="index") 
        )
        return session_seqs
